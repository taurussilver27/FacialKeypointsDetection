{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation,MaxPool1D, MaxPool2D, Conv1D, Conv2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATURES = False\n",
    "FEATURE_FILE_NAME = \"inception_features.npy\"\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname,test=False, cols=None):\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    if cols:\n",
    "        df = df[list(cols)+['Image']]\n",
    "    \n",
    "    #print( df.count())\n",
    "    df = df.dropna()\n",
    "    columns = df.columns\n",
    "    \n",
    "    X = np.vstack(df['Image'].values)#/255\n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    if not test:\n",
    "        y = df[df.columns[:-1]].values\n",
    "        #y = (y-48)/48\n",
    "        X, y = shuffle(X, y, random_state=20)\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "        columns = None\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def load2d(fname,test=False, cols=None):\n",
    "    \n",
    "    X, y, columns = load(fname,test, cols)\n",
    "    X = X.reshape(-1,96,96, 1)\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def array_to_img(x):\n",
    "#     rgbimg = cv2.resize(cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),(224,224))\n",
    "    rgbimg = cv2.cvtColor(x,cv2.COLOR_GRAY2RGB)\n",
    "    rgbimg = rgbimg[...,::-1].astype(np.float32)\n",
    "    a = np.expand_dims(rgbimg, axis=0)\n",
    "    a = preprocess_input(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, columns = load2d(\"data/training.csv\",test=False)\n",
    "columns = np.array(list(columns[:-1]))\n",
    "columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_features = []\n",
    "inception_features_array = np.zeros([X_train.shape[0],2048])\n",
    "\n",
    "if EXTRACT_FEATURES:\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if(i%10 == 0):\n",
    "            print('.',end='')\n",
    "        img = array_to_img(X_train[i])\n",
    "        features = inception_model.predict(img)\n",
    "#         print(features.shape)\n",
    "        inception_features_array[i] = features.flatten()\n",
    "    file = open(FEATURE_FILE_NAME,\"wb\")\n",
    "#     inception_features_array = np.array(inception_features)\n",
    "    np.save(file,inception_features_array)\n",
    "else:\n",
    "    file = open(FEATURE_FILE_NAME,'rb')\n",
    "    inception_features_array = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(32,3,strides=1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "#model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv1D(64,2,strides=1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "#model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv1D(128,2,strides=1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "#model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(30))\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;34m'This model has not yet been built. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m                 \u001b[1;34m'Build the model first by calling build() '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                 \u001b[1;34m'or calling fit() with some data. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1546 samples, validate on 273 samples\n",
      "Epoch 1/10\n",
      " - 311s - loss: 187.4077 - acc: 0.7044 - val_loss: 191.6057 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 191.60572, saving model to face_model_in1_cnn.h5\n",
      "Epoch 2/10\n",
      " - 311s - loss: 186.9652 - acc: 0.6908 - val_loss: 189.9089 - val_acc: 0.6777\n",
      "\n",
      "Epoch 00002: val_loss improved from 191.60572 to 189.90895, saving model to face_model_in1_cnn.h5\n",
      "Epoch 3/10\n",
      " - 311s - loss: 186.6950 - acc: 0.7025 - val_loss: 188.9948 - val_acc: 0.6264\n",
      "\n",
      "Epoch 00003: val_loss improved from 189.90895 to 188.99475, saving model to face_model_in1_cnn.h5\n",
      "Epoch 4/10\n",
      " - 311s - loss: 186.2976 - acc: 0.6966 - val_loss: 195.7082 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 188.99475\n",
      "Epoch 5/10\n",
      " - 324s - loss: 185.9715 - acc: 0.7122 - val_loss: 191.3685 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 188.99475\n",
      "Epoch 6/10\n",
      " - 339s - loss: 185.6777 - acc: 0.7076 - val_loss: 189.8553 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 188.99475\n",
      "Epoch 7/10\n",
      " - 362s - loss: 185.4136 - acc: 0.7135 - val_loss: 189.6116 - val_acc: 0.6593\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 188.99475\n",
      "Epoch 8/10\n",
      " - 352s - loss: 185.1419 - acc: 0.7296 - val_loss: 190.7759 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 188.99475\n",
      "Epoch 9/10\n",
      " - 311s - loss: 184.8667 - acc: 0.7232 - val_loss: 188.8867 - val_acc: 0.6886\n",
      "\n",
      "Epoch 00009: val_loss improved from 188.99475 to 188.88669, saving model to face_model_in1_cnn.h5\n",
      "Epoch 10/10\n",
      " - 312s - loss: 184.7080 - acc: 0.7270 - val_loss: 196.1526 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 188.88669\n"
     ]
    }
   ],
   "source": [
    "# save best weights\n",
    "checkpointer = ModelCheckpoint(filepath='face_model_in1_cnn.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# num epochs\n",
    "epochs = 10\n",
    "model.load_weights(\"face_model_in1_cnn.h5\")\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(inception_features_array, y, test_size=0.15, random_state=42)\n",
    "# run model\n",
    "inception_features_array = np.expand_dims(inception_features_array, axis=2)\n",
    "hist = model.fit(inception_features_array,y_train,batch_size=1,epochs=epochs, \n",
    "                 validation_split=0.15, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "# save model to json\n",
    "model_json = model.to_json()\n",
    "with open(\"face_model_in1_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 1ms/step\n",
      "194.1385484737028 0.6915887850467289\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(\"face_model_in1_cnn.h5\")\n",
    "inception_features_array_test = np.zeros([X_test.shape[0],2048])\n",
    "for i in range(X_test.shape[0]):\n",
    "    img = array_to_img(X_test[i])\n",
    "    features = inception_model.predict(img)\n",
    "    inception_features_array_test[i] = features.flatten()\n",
    "inception_features_array_test = np.expand_dims(inception_features_array_test,axis=2)\n",
    "score, acc = model.evaluate(inception_features_array_test,y_test)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
