{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, MaxPool2D, Conv2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATURES = False\n",
    "FEATURE_FILE_NAME = \"inception_features.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname,test=False, cols=None):\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    if cols:\n",
    "        df = df[list(cols)+['Image']]\n",
    "    \n",
    "    #print( df.count())\n",
    "    df = df.dropna()\n",
    "    columns = df.columns\n",
    "    \n",
    "    X = np.vstack(df['Image'].values)#/255\n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    if not test:\n",
    "        y = df[df.columns[:-1]].values\n",
    "        #y = (y-48)/48\n",
    "        X, y = shuffle(X, y, random_state=20)\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "        columns = None\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def load2d(fname,test=False, cols=None):\n",
    "    \n",
    "    X, y, columns = load(fname,test, cols)\n",
    "    X = X.reshape(-1,96,96, 1)\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def array_to_img(x):\n",
    "    rgbimg = cv2.resize(cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),(224,224))\n",
    "    rgbimg = rgbimg[...,::-1].astype(np.float32)\n",
    "    a = np.expand_dims(rgbimg, axis=0)\n",
    "    a = preprocess_input(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n",
       "       'right_eye_center_y', 'left_eye_inner_corner_x',\n",
       "       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n",
       "       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',\n",
       "       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',\n",
       "       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n",
       "       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',\n",
       "       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',\n",
       "       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n",
       "       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',\n",
       "       'mouth_left_corner_x', 'mouth_left_corner_y',\n",
       "       'mouth_right_corner_x', 'mouth_right_corner_y',\n",
       "       'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
       "       'mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'],\n",
       "      dtype='<U25')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, columns = load2d(\"data/training.csv\",test=False)\n",
    "columns = np.array(list(columns[:-1]))\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimg = X[0]\n",
    "# rgbimg = cv2.resize(cv2.cvtColor(mimg,cv2.COLOR_GRAY2RGB),(224,224))\n",
    "# cv2.imwrite(\"rgb.jpg\",rgbimg)\n",
    "# rgbimg = rgbimg[...,::-1].astype(np.float32)\n",
    "\n",
    "# rgbimg.shape\n",
    "# a = np.expand_dims(rgbimg, axis=0)\n",
    "# print(a.shape)\n",
    "\n",
    "# a = preprocess_input(a)\n",
    "# # plt.imshow(rgbimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img(\"rgb.jpg\", target_size=(224, 224))\n",
    "# # print(img.shape)\n",
    "# # convert image to numpy array\n",
    "# x = image.img_to_array(img)\n",
    "# print(x.shape)\n",
    "# # the image is now in an array of shape (3, 224, 224) \n",
    "# # need to expand it to (1, 3, 224, 224) as it's expecting a list\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = preprocess_input(x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# # print(x)\n",
    "# # extract the features\n",
    "# features = inception_model.predict(x)\n",
    "# # convert from Numpy to a list of values\n",
    "# features_arr = np.char.mod('%f', features)\n",
    "# print(features_arr.shape)\n",
    "# print(features.shape)\n",
    "# print(np.squeeze(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_features = []\n",
    "inception_features_array = np.zeros([X.shape[0],5,5,2048])\n",
    "\n",
    "if EXTRACT_FEATURES:\n",
    "    for i in range(X.shape[0]):\n",
    "        if(i%10 == 0):\n",
    "            print('.',end='')\n",
    "        img = array_to_img(X[i])\n",
    "        features = inception_model.predict(img)[0]\n",
    "        inception_features_array[i] = np.char.mod('%f', features)\n",
    "    file = open(FEATURE_FILE_NAME,\"w\")\n",
    "#     inception_features_array = np.array(inception_features)\n",
    "    np.save(file,inception_features_array)\n",
    "else:\n",
    "    file = open(FEATURE_FILE_NAME,'rb')\n",
    "    inception_features_array = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2140, 5, 5, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_features_array.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
