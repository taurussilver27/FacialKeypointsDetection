{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation,MaxPool1D, MaxPool2D, Conv1D, Conv2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATURES = False\n",
    "FEATURE_FILE_NAME = \"inception_features.npy\"\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname,test=False, cols=None):\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    if cols:\n",
    "        df = df[list(cols)+['Image']]\n",
    "    \n",
    "    #print( df.count())\n",
    "    df = df.dropna()\n",
    "    columns = df.columns\n",
    "    \n",
    "    X = np.vstack(df['Image'].values)#/255\n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    if not test:\n",
    "        y = df[df.columns[:-1]].values\n",
    "        #y = (y-48)/48\n",
    "        X, y = shuffle(X, y, random_state=20)\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "        columns = None\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def load2d(fname,test=False, cols=None):\n",
    "    \n",
    "    X, y, columns = load(fname,test, cols)\n",
    "    X = X.reshape(-1,96,96, 1)\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def array_to_img(x):\n",
    "#     rgbimg = cv2.resize(cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),(224,224))\n",
    "    rgbimg = cv2.cvtColor(x,cv2.COLOR_GRAY2RGB)\n",
    "    rgbimg = rgbimg[...,::-1].astype(np.float32)\n",
    "    a = np.expand_dims(rgbimg, axis=0)\n",
    "    a = preprocess_input(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, columns = load2d(\"data/training.csv\",test=False)\n",
    "columns = np.array(list(columns[:-1]))\n",
    "columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_features = []\n",
    "inception_features_array = np.zeros([X_train.shape[0],2048])\n",
    "\n",
    "if EXTRACT_FEATURES:\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if(i%10 == 0):\n",
    "            print('.',end='')\n",
    "        img = array_to_img(X_train[i])\n",
    "        features = inception_model.predict(img)\n",
    "#         print(features.shape)\n",
    "        inception_features_array[i] = features.flatten()\n",
    "    file = open(FEATURE_FILE_NAME,\"wb\")\n",
    "#     inception_features_array = np.array(inception_features)\n",
    "    np.save(file,inception_features_array)\n",
    "else:\n",
    "    file = open(FEATURE_FILE_NAME,'rb')\n",
    "    inception_features_array = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(32,3,input_shape=(2048,1),strides=1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv1D(64,2,strides=1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Conv1D(128,2,strides=1))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "model.add(Dropout(0.15))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(30))\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_99 (Batc (None, 2048, 1)           4         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 2046, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 2046, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 1023, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1023, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 1022, 64)          4160      \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 1022, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 511, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 511, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 510, 128)          16512     \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 510, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 255, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 255, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32640)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 500)               16320500  \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                15030     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 16,356,334\n",
      "Trainable params: 16,356,332\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1546 samples, validate on 273 samples\n",
      "Epoch 1/10\n",
      " - 315s - loss: 232.1631 - acc: 0.7206 - val_loss: 233.5034 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 233.50335, saving model to face_model_in1_cnn.h5\n",
      "Epoch 2/10\n",
      " - 308s - loss: 231.6491 - acc: 0.7160 - val_loss: 233.7287 - val_acc: 0.7070\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 233.50335\n",
      "Epoch 3/10\n",
      " - 307s - loss: 231.1897 - acc: 0.7128 - val_loss: 234.6434 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 233.50335\n",
      "Epoch 4/10\n",
      " - 307s - loss: 230.8190 - acc: 0.7232 - val_loss: 235.0112 - val_acc: 0.7070\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 233.50335\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-33c6adf0698f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#inception_features_array = np.expand_dims(inception_features_array, axis=2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m hist = model.fit(inception_features_array,y_train,batch_size=1,epochs=epochs, \n\u001b[1;32m---> 12\u001b[1;33m                  validation_split=0.15, callbacks=[checkpointer], verbose=2)\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# save model to json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# save best weights\n",
    "checkpointer = ModelCheckpoint(filepath='face_model_in1_cnn.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# num epochs\n",
    "epochs = 10\n",
    "model.load_weights(\"face_model_in1_cnn.h5\") #already done 10 epochs\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(inception_features_array, y, test_size=0.15, random_state=42)\n",
    "# run model\n",
    "inception_features_array = np.expand_dims(inception_features_array, axis=2)\n",
    "hist = model.fit(inception_features_array,y_train,batch_size=1,epochs=epochs, \n",
    "                 validation_split=0.15, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "# save model to json\n",
    "model_json = model.to_json()\n",
    "with open(\"face_model_in1_cnn.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 1s 2ms/step\n",
      "231.58096418053933 0.6947040498442367\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(\"face_model_in1_cnn.h5\")\n",
    "inception_features_array_test = np.zeros([X_test.shape[0],2048])\n",
    "for i in range(X_test.shape[0]):\n",
    "    img = array_to_img(X_test[i])\n",
    "    features = inception_model.predict(img)\n",
    "    inception_features_array_test[i] = features.flatten()\n",
    "inception_features_array_test = np.expand_dims(inception_features_array_test,axis=2)\n",
    "score, acc = model.evaluate(inception_features_array_test,y_test)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
