{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, MaxPool1D,MaxPool2D,Conv1D, Conv2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import shuffle\n",
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATURES = False\n",
    "FEATURE_FILE_NAME = \"inception_features.npy\"\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname,test=False, cols=None):\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    if cols:\n",
    "        df = df[list(cols)+['Image']]\n",
    "    \n",
    "    #print( df.count())\n",
    "    df = df.dropna()\n",
    "    columns = df.columns\n",
    "    \n",
    "    X = np.vstack(df['Image'].values)#/255\n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    if not test:\n",
    "        y = df[df.columns[:-1]].values\n",
    "        #y = (y-48)/48\n",
    "        X, y = shuffle(X, y, random_state=20)\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "        columns = None\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def load2d(fname,test=False, cols=None):\n",
    "    \n",
    "    X, y, columns = load(fname,test, cols)\n",
    "    X = X.reshape(-1,96,96, 1)\n",
    "    \n",
    "    return X, y, columns\n",
    "\n",
    "def array_to_img(x):\n",
    "#     rgbimg = cv2.resize(cv2.cvtColor(x,cv2.COLOR_GRAY2RGB),(224,224))\n",
    "    rgbimg = cv2.cvtColor(x,cv2.COLOR_GRAY2RGB)\n",
    "    rgbimg = rgbimg[...,::-1].astype(np.float32)\n",
    "    a = np.expand_dims(rgbimg, axis=0)\n",
    "    a = preprocess_input(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, columns = load2d(\"data/training.csv\",test=False)\n",
    "columns = np.array(list(columns[:-1]))\n",
    "columns\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimg = X[0]\n",
    "# rgbimg = cv2.resize(cv2.cvtColor(mimg,cv2.COLOR_GRAY2RGB),(224,224))\n",
    "# cv2.imwrite(\"rgb.jpg\",rgbimg)\n",
    "# rgbimg = rgbimg[...,::-1].astype(np.float32)\n",
    "\n",
    "# rgbimg.shape\n",
    "# a = np.expand_dims(rgbimg, axis=0)\n",
    "# print(a.shape)\n",
    "\n",
    "# a = preprocess_input(a)\n",
    "# # plt.imshow(rgbimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img(\"rgb.jpg\", target_size=(224, 224))\n",
    "# # print(img.shape)\n",
    "# # convert image to numpy array\n",
    "# x = image.img_to_array(img)\n",
    "# print(x.shape)\n",
    "# # the image is now in an array of shape (3, 224, 224) \n",
    "# # need to expand it to (1, 3, 224, 224) as it's expecting a list\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = preprocess_input(x)\n",
    "# print(x.shape)\n",
    "\n",
    "\n",
    "# # print(x)\n",
    "# # extract the features\n",
    "# features = inception_model.predict(x)\n",
    "# # convert from Numpy to a list of values\n",
    "# features_arr = np.char.mod('%f', features)\n",
    "# print(features_arr.shape)\n",
    "# print(features.shape)\n",
    "# print(np.squeeze(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_features = []\n",
    "inception_features_array = np.zeros([X_train.shape[0],2048])\n",
    "\n",
    "if EXTRACT_FEATURES:\n",
    "    for i in range(X_train.shape[0]):\n",
    "        if(i%10 == 0):\n",
    "            print('.',end='')\n",
    "        img = array_to_img(X_train[i])\n",
    "        features = inception_model.predict(img)\n",
    "#         print(features.shape)\n",
    "        inception_features_array[i] = features.flatten()\n",
    "    file = open(FEATURE_FILE_NAME,\"wb\")\n",
    "#     inception_features_array = np.array(inception_features)\n",
    "    np.save(file,inception_features_array)\n",
    "else:\n",
    "    file = open(FEATURE_FILE_NAME,'rb')\n",
    "    inception_features_array = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception_features_array.shape\n",
    "# (inception_features_array.reshape(inception_features_array.shape[0],-1))[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception_features_array = (inception_features_array.reshape(inception_features_array.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Conv1D(128,3,input_shape=(2048,1)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPool1D(pool_size=2,strides=2))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(30))\n",
    "\n",
    "model.add(Conv2D(24, 5, data_format=\"channels_last\", kernel_initializer=\"he_normal\", \n",
    "                  padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(36, 5))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(48, 5))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(90))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(30))\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1819, 2048, 1)\n"
     ]
    }
   ],
   "source": [
    "inception_features_array  = np.expand_dims(inception_features_array, axis=2)\n",
    "print(inception_features_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_95: expected ndim=4, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f8ef44be4af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# inception_features_array = inception_features_array.reshape(inception_features_array.shape[0],32,64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m hist = model.fit(inception_features_array,y_train, epochs=epochs, \n\u001b[0;32m---> 12\u001b[0;31m                  validation_split=0.15, callbacks=[checkpointer], verbose=2)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# save model to json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m# to match the value shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_95: expected ndim=4, found ndim=3"
     ]
    }
   ],
   "source": [
    "# save best weights\n",
    "checkpointer = ModelCheckpoint(filepath='face_model_in_cnn_ds.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# num epochs\n",
    "epochs = 50\n",
    "\n",
    "# model.load_weights('face_model_in_cnn_ds.h5')\n",
    "# X_train, X_test, y_train, y_test = train_test_split(inception_features_array, y, test_size=0.15, random_state=42)\n",
    "# run model\n",
    "# inception_features_array = inception_features_array.reshape(inception_features_array.shape[0],32,64)\n",
    "hist = model.fit(inception_features_array,y_train, epochs=epochs, \n",
    "                 validation_split=0.15, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "# save model to json\n",
    "model_json = model.to_json()\n",
    "with open(\"face_model_in_cnn_ds.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoint_predict(x):\n",
    "    img = array_to_img(x)\n",
    "    features = (inception_model.predict(img)).flatten()\n",
    "#     print(features.shape)\n",
    "#     print(np.array([[features]]).shape)\n",
    "    return model.predict(features.reshape(1,2048,1))[0]\n",
    "\n",
    "import seaborn as sns\n",
    "plt.figure(0, figsize=(12,6))\n",
    "for i in range(1, 13):\n",
    "    plt.subplot(3,4,i)\n",
    "    plt.imshow(X_test[i, :, :, 0], cmap=\"gray\")\n",
    "    p = keypoint_predict(X_test[i])\n",
    "    plt.scatter(p[range(0, 30, 2)], p[range(1, 30, 2)], marker='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_features_array_test = np.zeros([X_test.shape[0],2048])\n",
    "for i in range(X_test.shape[0]):\n",
    "    img = array_to_img(X_test[i])\n",
    "    features = inception_model.predict(img)\n",
    "    inception_features_array_test[i] = features.flatten()\n",
    "\n",
    "inception_features_array_test  = np.expand_dims(inception_features_array_test, axis=2)\n",
    "score, acc = model.evaluate(inception_features_array_test,y_test)\n",
    "print(score, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
